name: YouTube News Metadata Daily Crawl

on:
  schedule:
    - cron: '0 18 * * *'   # KST 03:00
  workflow_dispatch:

jobs:
  run-crawler:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: true

      - name: Set up Python environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          python -m pip install --upgrade packaging
          pip install -r requirements.txt
          pip check

      # --- 디버깅 & 존재 검증 ---
      - name: List files in repository root
        run: ls -R .

      - name: Check data directory contents
        run: |
          ls -l || true
          ls -l data || true
          echo "---- LFS status ----"
          git lfs version || true
          git lfs ls-files || true

      - name: Verify CSV (case-sensitive)
        run: |
          set -e
          FILE="data/youtube_news_channel_list.csv"
          if [ ! -f "$FILE" ]; then
            echo "❌ Not found: $FILE (대소문자/경로 확인 필요)"
            echo "Candidates:"
            find . -maxdepth 3 -iname "*youtube*news*channel*list*.csv" -print || true
            exit 1
          else
            echo "✅ Found: $FILE"
          fi

      - name: Run YouTube Crawler Script
        working-directory: ${{ github.workspace }}
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          python collect_news_metadata.py

      - name: Upload artifact (metadata)
        uses: actions/upload-artifact@v4
        with:
          name: youtube-output-${{ github.run_number }}
          path: out/*.csv.gz
          if-no-files-found: error
          retention-days: 60
          compression-level: 9
